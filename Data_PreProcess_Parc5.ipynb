{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from random import randint\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Data loading\n",
    "The dataset containing a subset of the Human Connectome Project data. \n",
    "It contains a total of 285 participants and a total of 330 cases.\n",
    "\n",
    "The images for one case are stored in its own specific folder, i.e. sub-XX where XX is the HCP participant labell. Note that 45 of them (distinguished in their name by *-V2) are follow-up scans of the same participant. Thus, if you want to consider only one case per participant, you should discard the *-V2s.\n",
    "\n",
    "- sub-XX_T1w.nii.gz which is the original T1w image (input of the system)\n",
    "- sub-XX_T1w._brainmask.nii.gz which is the brainmask used for the generation of the 5 different scales of parcellation\n",
    "- sub-XX_class-CSF_T1w and sub_class-WM_T1w are masks of the CSF/ White Matter tissues estimated by Freesurfer during the parcellation pipeline..\n",
    "- sub-XX_parc_scaleZ which is the parcellation (labels) for scale Z. scale1 corresponds to the 83 labels generated by freesurfer. scale2->5 correspond to parcellations at a finer scale. I guess we could start using scale1 as the output of the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dir = '/home/xiaoyu/ds-hcp/T1_image'\n",
    "parc5_dir = '/home/xiaoyu/ds-hcp/parc_5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject num:\n",
      "330\n",
      "\n",
      "Parc5 num:\n",
      "330\n"
     ]
    }
   ],
   "source": [
    "sub_list = os.listdir(sub_dir)\n",
    "print('Subject num:')\n",
    "print(len(sub_list))\n",
    "parc5_list = os.listdir(parc5_dir)\n",
    "print('\\nParc5 num:')\n",
    "print(len(parc5_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Slice the 3D MRI T1w data\n",
    "There are 330 3D MRI T1w data, for each T1w data, there will be 3 planes, i.e. Axial plane, Coronal plane and Sagittal plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over 330 T1w data\n",
    "for i in range(330):\n",
    "    sub_str = sub_list[i]\n",
    "    sub_nifti = nib.load(os.path.join(sub_dir,sub_str))\n",
    "    sub_arr = sub_nifti.get_fdata()\n",
    "    sub_tensor = torch.from_numpy(sub_arr)\n",
    "    # get the Axial plane. Get 182 images for each T1w data, image size is 182x217\n",
    "    for j in range(182):\n",
    "        axial_slice = sub_tensor[:,:,j]\n",
    "        axial_arr = axial_slice.byte().numpy()\n",
    "        axial_im = Image.fromarray(axial_arr)\n",
    "        axial_im.save('/home/xiaoyu/MRIdata/T1w/axial/sub{}/slice_{}.jpg'.format(i,j))\n",
    "    for k in range(217):\n",
    "        sagittal_slice = sub_tensor[:,k,:]\n",
    "        sagittal_arr = sagittal_slice.byte().numpy()\n",
    "        sagittal_im = Image.fromarray(sagittal_arr)\n",
    "        sagittal_im.save('/home/xiaoyu/MRIdata/T1w/sagittal/sub{}/slice_{}.jpg'.format(i,k))\n",
    "    for m in range(182):\n",
    "        coronal_slice = sub_tensor[m,:,:]\n",
    "        coronal_arr = coronal_slice.byte().numpy()\n",
    "        coronal_im = Image.fromarray(coronal_arr)\n",
    "        coronal_im.save('/home/xiaoyu/MRIdata/T1w/coronal/sub{}/slice_{}.jpg'.format(i,m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Slice the 3D parcellation scale 5 data\n",
    "There are 330 3D MRI parcellation scale-5 data. For each parc_5 data, there will be 3 planes, the slice is the same for T1w data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over 330 parcellation scale-5 data\n",
    "for i in range(330):\n",
    "    parc5_str = parc5_list[i]\n",
    "    parc5_nifti = nib.load(os.path.join(parc5_dir,parc5_str))\n",
    "    parc5_arr = parc5_nifti.get_fdata()\n",
    "    parc5_tensor = torch.from_numpy(parc5_arr)\n",
    "\n",
    "    for j in range(182):\n",
    "        axial_slice = parc5_tensor[:,:,j]\n",
    "        axial_arr = axial_slice.byte().numpy()\n",
    "        axial_im = Image.fromarray(axial_arr)\n",
    "        axial_im.save('/home/xiaoyu/MRIdata/parc_5/axial/sub{}/slice_{}.jpg'.format(i,j))\n",
    "    for k in range(217):\n",
    "        sagittal_slice = parc5_tensor[:,k,:]\n",
    "        sagittal_arr = sagittal_slice.byte().numpy()\n",
    "        sagittal_im = Image.fromarray(sagittal_arr)\n",
    "        sagittal_im.save('/home/xiaoyu/MRIdata/parc_5/sagittal/sub{}/slice_{}.jpg'.format(i,k))\n",
    "    for m in range(182):\n",
    "        coronal_slice = parc5_tensor[m,:,:]\n",
    "        coronal_arr = coronal_slice.byte().numpy()\n",
    "        coronal_im = Image.fromarray(coronal_arr)\n",
    "        coronal_im.save('/home/xiaoyu/MRIdata/parc_5/coronal/sub{}/slice_{}.jpg'.format(i,m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
