{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform\n",
    "from torchvision import transforms, utils\n",
    "import torch\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from random import randint\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import QuickNAT as QN\n",
    "import torch.nn as nn\n",
    "from livelossplot import PlotLosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id = 1\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3308688\n"
     ]
    }
   ],
   "source": [
    "model = QN.QuickNAT(1,64,256)\n",
    "model_params = list(model.parameters())\n",
    "nb_param=0\n",
    "for param in model.parameters():\n",
    "    nb_param+=np.prod(list(param.data.size()))\n",
    "print(nb_param)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    \"\"\"Training dataset with mask image mapping to classes\"\"\"\n",
    "    def __init__(self, T1a_dir, parc5a_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            T1a_dir (string): Directory with T1w image in axial plane\n",
    "            transform (callable): Optional transform to be applied on a sample\n",
    "            parc5a_dir (string): Directory with parcellation scale 5 in axial plane\n",
    "        \"\"\"\n",
    "        self.T1a_dir = T1a_dir\n",
    "        self.transform = transform\n",
    "        self.parc5a_dir = parc5a_dir\n",
    "        \n",
    "    def __len__(self):\n",
    "        T1a_list = os.listdir(self.T1a_dir)\n",
    "        return len(T1a_list)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        T1a_list = os.listdir(T1a_dir)\n",
    "        parc5a_list = os.listdir(parc5a_dir)\n",
    "        \n",
    "        T1a_str = T1a_list[idx]\n",
    "        \n",
    "        T1a_arr = io.imread(os.path.join(T1a_dir, T1a_str))\n",
    "        T1a_tensor = torch.from_numpy(T1a_arr)\n",
    "        \n",
    "        compose_T1 = transforms.Compose([transforms.ToPILImage(), \n",
    "                                         transforms.Resize((128,128),interpolation=Image.NEAREST),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        T1a_tensor = torch.unsqueeze(T1a_tensor, dim = 0)\n",
    "        T1a_tensor = compose_T1(T1a_tensor)\n",
    "              \n",
    "        parc5a_str = parc5a_list[idx]\n",
    "    \n",
    "        parc5a_arr = io.imread(os.path.join(parc5a_dir, parc5a_str))\n",
    "        parc5a_tensor = torch.from_numpy(parc5a_arr)\n",
    "        \n",
    "        compose = transforms.Compose([transforms.ToPILImage(),\n",
    "                                      transforms.Resize((128,128),interpolation=Image.NEAREST), \n",
    "                                      transforms.ToTensor()])\n",
    "        \n",
    "        parc5a_tensor = torch.unsqueeze(parc5a_tensor, dim = 0)\n",
    "        parc5a_tensor = compose(parc5a_tensor)\n",
    "        parc5a_tensor = parc5a_tensor.squeeze()\n",
    "        \n",
    "        parc5a_tensor = torch.round(parc5a_tensor / 0.0039).byte()\n",
    "      \n",
    "        sample = {'T1a':T1a_tensor, 'parc5a':parc5a_tensor}\n",
    "        \n",
    "        if self.transform:\n",
    "            T1a = self.transform(T1a_tensor)\n",
    "            sample = {'T1a':T1a, 'parc5a':parc5a}\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss:\n",
      "training   (min:    0.775, max:    0.857, cur:    0.852)\n",
      "Finish Training\n",
      "\n",
      "Subject num: 5\n",
      "epoch= 0 \t time= 1.0192909002304078 min \t loss= 0.8585882541295644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyu/miniconda3/envs/deep_mol/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyu/miniconda3/envs/deep_mol/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyu/miniconda3/envs/deep_mol/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/xiaoyu/miniconda3/envs/deep_mol/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyu/miniconda3/envs/deep_mol/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyu/miniconda3/envs/deep_mol/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyu/miniconda3/envs/deep_mol/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyu/miniconda3/envs/deep_mol/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyu/miniconda3/envs/deep_mol/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/xiaoyu/miniconda3/envs/deep_mol/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/xiaoyu/miniconda3/envs/deep_mol/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/xiaoyu/miniconda3/envs/deep_mol/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xiaoyu/miniconda3/envs/deep_mol/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/xiaoyu/miniconda3/envs/deep_mol/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/xiaoyu/miniconda3/envs/deep_mol/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/xiaoyu/miniconda3/envs/deep_mol/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a06c1831348b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;31m# Define the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_mol/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_mol/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "liveloss = PlotLosses()\n",
    "for iteration in range(50):\n",
    "    start=time.time()\n",
    "    logs = {}\n",
    "    for sub_idx in range(330):\n",
    "\n",
    "        T1a_dir = '/home/xiaoyu/MRIdata/T1w/axial/sub{}'.format(sub_idx)\n",
    "   \n",
    "        parc5a_dir = '/home/xiaoyu/MRIdata/parc_5/axial/sub{}'.format(sub_idx)\n",
    "   \n",
    "        T1a_list = os.listdir(T1a_dir)\n",
    "  \n",
    "        parc5a_list = os.listdir(parc5a_dir)\n",
    "\n",
    "    \n",
    "        if sub_idx == 0: # set sub0 as test set.\n",
    "            print('\\nT1w Axial slices num:',len(T1a_list))\n",
    "            print('\\nParc5 Axial slices num:',len(parc5a_list))\n",
    "\n",
    "            continue\n",
    "        \n",
    "        print('\\nSubject num:',sub_idx)   \n",
    "        train_data = TrainDataset(T1a_dir=T1a_dir, parc5a_dir = parc5a_dir)\n",
    "        dataloader = DataLoader(train_data, batch_size = 5, shuffle = True, num_workers = 4)\n",
    "    \n",
    "        criterion = nn.NLLLoss()\n",
    "        optimizer = optim.Adam(model.parameters() ,lr=0.001)\n",
    "    \n",
    "        for epoch in range(0,2):\n",
    "   \n",
    "    \n",
    "            # define the running loss\n",
    "            running_loss = 0\n",
    "            running_error = 0\n",
    "            num_batches=0\n",
    "      \n",
    "            for i_batch, sample_batched in enumerate(dataloader):\n",
    "        \n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "                #get the inputs\n",
    "                inputs, labels = sample_batched['T1a'], sample_batched['parc5a']\n",
    "        \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                inputs.requires_grad_()\n",
    "        \n",
    "                #forward + backward +optimize\n",
    "                scores = model(inputs)\n",
    "          \n",
    "                # Define the loss\n",
    "                loss = criterion(scores, labels.long()) \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "                # compute and accumulate stats\n",
    "                running_loss += loss.detach().item()\n",
    "       \n",
    "                num_batches+=1 \n",
    "    \n",
    "            # AVERAGE STATS THEN DISPLAY    \n",
    "            total_loss = running_loss/num_batches\n",
    "   \n",
    "            elapsed = (time.time()-start)/60\n",
    "        \n",
    "            print('epoch=',epoch, '\\t time=', elapsed,'min', '\\t loss=', total_loss )\n",
    "            logs['log loss'] = total_loss\n",
    "       \n",
    "        print('Finish Training')\n",
    "    print(iteration,'Iteration')\n",
    "    liveloss.update(logs)\n",
    "    liveloss.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
