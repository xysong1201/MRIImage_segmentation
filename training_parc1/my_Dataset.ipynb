{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset,  WeightedRandomSampler\n",
    "from skimage import io, transform\n",
    "from torchvision import transforms, utils\n",
    "import torch\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from random import randint\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import QuickNAT as QN\n",
    "import torch.nn as nn\n",
    "from my_Dataset import TrainDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    \"\"\"Training dataset with mask image mapping to classes\"\"\"\n",
    "    def __init__(self, T1a_dir, parc1a_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            T1a_dir (string): Directory with T1w image in axial plane\n",
    "            transform (callable): Optional transform to be applied on a sample\n",
    "            parc1a_dir (string): Directory with parcellation scale 5 in axial plane\n",
    "        \"\"\"\n",
    "        self._T1a_dir = T1a_dir\n",
    "        self.transform = transform\n",
    "        self._parc1a_dir = parc1a_dir\n",
    "#         self.mapping = {\n",
    "#             180:91\n",
    "#         }\n",
    "        \n",
    "#     def mask_to_class(self, mask):\n",
    "#         for k in self.mapping:\n",
    "#             mask[mask==k] = self.mapping[k]\n",
    "#         return mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        T1a_list = os.listdir(self._T1a_dir)\n",
    "        return len(T1a_list)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        T1a_list = os.listdir(self._T1a_dir)\n",
    "        parc1a_list = os.listdir(self._parc1a_dir)\n",
    "        \n",
    "        T1a_str = T1a_list[idx]\n",
    "        \n",
    "        T1a_arr = io.imread(os.path.join(self._T1a_dir, T1a_str))\n",
    "        T1a_tensor = torch.from_numpy(T1a_arr)\n",
    "        \n",
    "        compose_T1 = transforms.Compose([transforms.ToPILImage(), \n",
    "                                         transforms.Resize((128,128),interpolation=Image.NEAREST),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        T1a_tensor = torch.unsqueeze(T1a_tensor, dim = 0)\n",
    "        T1a_tensor = compose_T1(T1a_tensor)\n",
    "              \n",
    "        parc1a_str = parc1a_list[idx]\n",
    "    \n",
    "        parc1a_arr = io.imread(os.path.join(self._parc1a_dir, parc1a_str))\n",
    "        parc1a_tensor = torch.from_numpy(parc1a_arr)\n",
    "        \n",
    "        compose = transforms.Compose([transforms.ToPILImage(),\n",
    "                                      transforms.Resize((128,128),interpolation=Image.NEAREST), \n",
    "                                      transforms.ToTensor()])\n",
    "        \n",
    "        parc1a_tensor = torch.unsqueeze(parc1a_tensor, dim = 0)\n",
    "        parc1a_tensor = compose(parc1a_tensor)\n",
    "        parc1a_tensor = parc1a_tensor.squeeze()\n",
    "        \n",
    "        parc1a_tensor = torch.round(parc1a_tensor / 0.0039).byte()\n",
    "        \n",
    "#         parc1a_tensor = self.mask_to_class(parc1a_tensor)\n",
    "      \n",
    "        sample = {'T1a':T1a_tensor, 'parc1a':parc1a_tensor}\n",
    "        \n",
    "        if self.transform:\n",
    "            T1a = self.transform(T1a_tensor)\n",
    "            sample = {'T1a':T1a, 'parc1a':parc1a}\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_idx = 0\n",
    "slice_idx = 5\n",
    "T1a_dir = '/home/xiaoyu/MRIdata_group/T1w/axial/sub{}/slice{}'.format(sub_idx,slice_idx)\n",
    "parc1a_dir = '/home/xiaoyu/MRIdata_group/parc_1/axial/sub{}/slice{}'.format(sub_idx,slice_idx)\n",
    "total_data = TrainDataset(T1a_dir=T1a_dir, parc1a_dir = parc1a_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300\n"
     ]
    }
   ],
   "source": [
    "for sub_idx in range(1,330):\n",
    "    T1a_dir = '/home/xiaoyu/MRIdata_group/T1w/axial/sub{}/slice{}'.format(sub_idx,slice_idx)\n",
    "    parc1a_dir = '/home/xiaoyu/MRIdata_group/parc_1/axial/sub{}/slice{}'.format(sub_idx,slice_idx)\n",
    "    train_data = TrainDataset(T1a_dir=T1a_dir, parc1a_dir = parc1a_dir)\n",
    "    total_data = total_data + train_data\n",
    "print(len(total_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
      " 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n",
      " 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n",
      " 145 146 149 155]\n",
      "[11870   169   159   138   124    82    89    57    54    55    42    38\n",
      "    25    23    26    22    17    13    17    26    18    15    24    23\n",
      "    34    42    36    34    35    80    42    38    32    20    18     6\n",
      "     8     5     2     4     4     6     7     6     3     5     9     5\n",
      "    13    16    15    12    14    14    18    23    21    20    36    34\n",
      "    41    39   413    43    38    31    33    32    30    26    24    30\n",
      "    24    21    17    23    12     7    19    20    16    25    21    26\n",
      "    24    31    36    31    30    23    27    30    32    33    29    25\n",
      "    26    15    24    22    13    19    13    15    11    15    17     7\n",
      "    10    13    14    15    11    11    11    17    24    27    22    18\n",
      "    29    40    33    28   240    31   168    28    27    20    17    18\n",
      "    14    14     7    20     3     5     8     4    11     8     8     2\n",
      "     1     2     2     1]\n",
      "------\n",
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n",
      "  14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n",
      "  28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n",
      "  42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n",
      "  56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n",
      "  70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n",
      "  84.  85.  86.  87.  88.  89.  90.  92.  93.  94.  95.  96.  97.  98.\n",
      "  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111. 112.\n",
      " 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125. 126.\n",
      " 127. 128. 129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139. 140.\n",
      " 141. 142. 143. 144. 145. 146. 149. 155.]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
      " 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n",
      " 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n",
      " 145 146 148 149 151 153 160]\n",
      "[11804   200   167   138   126    91    81    90    66    55    39    26\n",
      "    36    28    25    15    19    21    23    25    35    12    28    30\n",
      "    24    42    41    47    39    45    31    25    25    19    14    17\n",
      "    10     5     5     4     5     3    10     3     8     5    14    11\n",
      "    20    16    13    15    15    12    20    18    24    29    27    36\n",
      "    36    52   391    33    38    39    44    31    34    21    10    21\n",
      "    10    15    18    22    17    16    23    23    24    34    23    25\n",
      "    26    26    34    33    42    35    28    38    44    42    26    22\n",
      "    34    31    24    26    17    19    26    18    14    11     9    13\n",
      "     4    13     8     9    17    15    17    18    27    21    23    25\n",
      "    30    35    29    24   127    33   169    31    18    21    20    12\n",
      "    25    14    16    12    10     9     6     3     8     4     3     3\n",
      "     3     1     1     2     1     1     1]\n",
      "------\n",
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n",
      "  14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n",
      "  28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n",
      "  42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n",
      "  56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n",
      "  70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n",
      "  84.  85.  86.  87.  88.  89.  90.  92.  93.  94.  95.  96.  97.  98.\n",
      "  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111. 112.\n",
      " 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125. 126.\n",
      " 127. 128. 129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139. 140.\n",
      " 141. 142. 143. 144. 145. 146. 148. 149. 151. 153. 155. 160.]\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2\n",
      " 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "colors = torch.tensor([])\n",
    "for i in range(len(total_data)):\n",
    "    print('\\n')\n",
    "    sample = total_data[i]\n",
    "    target = sample['parc1a']\n",
    "    unique_color, count_ind = np.unique(target, return_counts = True)\n",
    "    print(unique_color)\n",
    "    print(count_ind)\n",
    "    colors = torch.cat((colors,torch.tensor(unique_color).float()))\n",
    "    unique_color, count_conc = np.unique(colors, return_counts = True)\n",
    "    print('------')\n",
    "    print(unique_color)\n",
    "    print(count_conc)\n",
    "    if i ==1:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 128])\n"
     ]
    }
   ],
   "source": [
    "sample = train_data[0]\n",
    "target = sample['parc1a']\n",
    "print(target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  13  14  15  16  17  18\n",
      "  19  21  30  31 101 106 112 113 117 118 119 120 123 124 125 126 127 128\n",
      " 129 130 131 132 133 135 137 138 139 140 141 142 143 146 154 156]\n",
      "52\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 138 is out of bounds for axis 0 with size 52",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-5eabb13801bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 138 is out of bounds for axis 0 with size 52"
     ]
    }
   ],
   "source": [
    "unique_color, count = np.unique(target, return_counts = True)\n",
    "print(unique_color)\n",
    "print(count.size)\n",
    "weight = 1. / count\n",
    "        \n",
    "sample_weight = torch.tensor([])\n",
    "        \n",
    "for x in range(target.size(0)):\n",
    "    for y in range(target.size(1)):\n",
    "        sample_weight = weight[target[x,y]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
