{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset,  WeightedRandomSampler\n",
    "from skimage import io, transform\n",
    "from torchvision import transforms, utils\n",
    "import torch\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from random import randint\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import QuickNAT as QN\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset of T1w image and brainmask image in axial plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    \"\"\"Training dataset with mask image mapping to classes\"\"\"\n",
    "    def __init__(self, T1a_dir, brainmask_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            T1a_dir (string): Directory with T1w image in axial plane\n",
    "            transform (callable): Optional transform to be applied on a sample\n",
    "            brainmask_dir (string): Directory with brainmask in axial plane\n",
    "        \"\"\"\n",
    "        self.T1a_dir = T1a_dir\n",
    "        self.transform = transform\n",
    "        self.brainmask_dir = brainmask_dir\n",
    "#         self.mapping = {\n",
    "#             180:91\n",
    "#         }\n",
    "        \n",
    "#     def mask_to_class(self, mask):\n",
    "#         for k in self.mapping:\n",
    "#             mask[mask==k] = self.mapping[k]\n",
    "#         return mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        T1a_list = os.listdir(self.T1a_dir)\n",
    "        return len(T1a_list)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        T1a_list = os.listdir(self.T1a_dir)\n",
    "        brainmask_list = os.listdir(self.brainmask_dir)\n",
    "        \n",
    "        T1a_str = T1a_list[idx]\n",
    "        \n",
    "        T1a_arr = io.imread(os.path.join(self.T1a_dir, T1a_str))\n",
    "        T1a_tensor = torch.from_numpy(T1a_arr)\n",
    "       \n",
    "        \n",
    "        compose_T1 = transforms.Compose([transforms.ToPILImage(),\n",
    "                                         transforms.Resize((128,128),interpolation=Image.NEAREST),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        \n",
    "        T1a_tensor = torch.unsqueeze(T1a_tensor, dim = 0)   \n",
    "\n",
    "        T1a_tensor = compose_T1(T1a_tensor)\n",
    "       \n",
    "        \n",
    "        # The original brainmask value is 0,1,2     \n",
    "        brainmask_str = brainmask_list[idx]\n",
    "    \n",
    "        brainmask_arr = io.imread(os.path.join(self.brainmask_dir, brainmask_str))\n",
    "        brainmask_tensor = torch.from_numpy(brainmask_arr)\n",
    "        \n",
    "        compose = transforms.Compose([transforms.ToPILImage(),\n",
    "                                      transforms.Resize((128,128),interpolation=Image.NEAREST), \n",
    "                                      transforms.ToTensor()])\n",
    "        \n",
    "        brainmask_tensor = torch.unsqueeze(brainmask_tensor, dim = 0)\n",
    "        brainmask_tensor = compose(brainmask_tensor)\n",
    "        brainmask_tensor = brainmask_tensor.squeeze()\n",
    "        \n",
    "     \n",
    "        # After the resize, the value of brainmask is 0, 0.0039 and 0.0078, so this formula below is used\n",
    "        # to make it to 0, 1, 2\n",
    "        brainmask_tensor = torch.round(brainmask_tensor / 0.0039).byte()   \n",
    "        \n",
    "#         parc1a_tensor = self.mask_to_class(parc1a_tensor)\n",
    "      \n",
    "        sample = {'T1a':T1a_tensor, 'brainmask':brainmask_tensor}\n",
    "        \n",
    "        if self.transform:\n",
    "            T1a = self.transform(T1a_tensor)\n",
    "            sample = {'T1a':T1a, 'brainmask':brainmask}\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the data in the directory MRIdata to count the number of 0, 1, 2, in order to define the weight of the target.\n",
    "* MRIdata directory contains all the sliced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n"
     ]
    }
   ],
   "source": [
    "# # subject 0, construct the first data in total_data\n",
    "# sub_idx = 0\n",
    "# T1a_dir = '/home/xiaoyu/MRIdata/T1w/axial/sub{}'.format(sub_idx)\n",
    "# brainmask_dir = '/home/xiaoyu/MRIdata/brainmask/axial/sub{}'.format(sub_idx)\n",
    "# total_data = TrainDataset(T1a_dir=T1a_dir, brainmask_dir = brainmask_dir)\n",
    "# print(len(total_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60060\n"
     ]
    }
   ],
   "source": [
    "# # Add up all the subject data\n",
    "# for sub_idx in range(1,330):\n",
    "#     T1a_dir = '/home/xiaoyu/MRIdata/T1w/axial/sub{}'.format(sub_idx)\n",
    "#     brainmask_dir = '/home/xiaoyu/MRIdata/brainmask/axial/sub{}'.format(sub_idx)\n",
    "#     train_data = TrainDataset(T1a_dir=T1a_dir, brainmask_dir = brainmask_dir)\n",
    "#     total_data = total_data + train_data\n",
    "# print(len(total_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total data of Group ID. (one group has 10 slices, so for 330 subjects, there are in total 3330 slices in one group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_total = torch.tensor([])\n",
    "\n",
    "# for i in range(len(total_data)):\n",
    "#     sample = total_data[i]\n",
    "#     mask = sample['brainmask'].float()\n",
    "#     mask_total = torch.cat((mask_total, mask))\n",
    "    \n",
    "# print(mask_total.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# gpu_id = 1\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "\n",
    "# device = torch.device('cuda')\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_total = torch.tensor([])\n",
    "# mask_total= mask_total.to(device)\n",
    "# # total_data = total_data.to(device)\n",
    "# for i in range(len(total_data)):\n",
    "#     sample = total_data[i]\n",
    "#     mask = sample['brainmask'].float()\n",
    "#     mask = mask.to(device)\n",
    "#     mask_total = torch.cat((mask_total, mask))\n",
    "    \n",
    "# print(mask_total.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_color, count = np.unique(mask_total.cpu(), return_counts = True)\n",
    "# print(count)\n",
    "# print(unique_color.size)\n",
    "# print(unique_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
