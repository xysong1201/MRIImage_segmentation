{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from skimage import io, transform\n",
    "from torchvision import transforms, utils\n",
    "import torch\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from random import randint\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import QuickNAT as QN\n",
    "import torch.nn as nn\n",
    "from my_Dataset import TrainDataset\n",
    "from weight_axial import weight\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "gpu_id = 0\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "print(device)\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "sub_idx = 0\n",
    "slice_idx = 3\n",
    "T1a_dir = '/home/xiaoyu/MRIdata_group/T1w/axial/sub{}/slice{}'.format(sub_idx,slice_idx)\n",
    "parc1a_dir = '/home/xiaoyu/MRIdata_group/parc_1/axial/sub{}/slice{}'.format(sub_idx,slice_idx)\n",
    "total_data = TrainDataset(T1a_dir=T1a_dir, parc1a_dir = parc1a_dir)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "for sub_idx in range(1,330):\n",
    "    T1a_dir = '/home/xiaoyu/MRIdata_group/T1w/axial/sub{}/slice{}'.format(sub_idx,slice_idx)\n",
    "    parc1a_dir = '/home/xiaoyu/MRIdata_group/parc_1/axial/sub{}/slice{}'.format(sub_idx,slice_idx)\n",
    "    train_data = TrainDataset(T1a_dir=T1a_dir, parc1a_dir = parc1a_dir)\n",
    "    total_data = total_data + train_data\n",
    "print(len(total_data))\n",
    "\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "print('The slice id is:',slice_idx)\n",
    "\n",
    "dataloader = DataLoader(total_data, batch_size = 4, shuffle = True, num_workers = 4)\n",
    "print(len(dataloader))\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "start=time.time()\n",
    "model = QN.QuickNAT(1,128,178)\n",
    "nb_param=0\n",
    "for param in model.parameters():\n",
    "    nb_param+=np.prod(list(param.data.size()))\n",
    "print(nb_param)\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "weight = weight.to(device)\n",
    "criterion = nn.NLLLoss(weight = weight)\n",
    "optimizer = optim.Adam(model.parameters() ,lr=0.001)\n",
    "# scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones = [200,400], gamma=0.1, last_epoch=-1)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.85)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "loss_list = []\n",
    "for epoch in range(0,2000):\n",
    "    running_loss = 0\n",
    "    num_batches = 0\n",
    "    scheduler.step()\n",
    "    for i_batch, sample_batched in enumerate(dataloader):\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #get the inputs\n",
    "        inputs, labels = sample_batched['T1a'], sample_batched['parc1a']\n",
    "        \n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        inputs.requires_grad_()\n",
    "        \n",
    "        #forward + backward +optimize\n",
    "        scores = model(inputs)\n",
    "\n",
    "          \n",
    "        # Define the loss\n",
    "        loss = criterion(scores, labels.long()) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # compute and accumulate stats\n",
    "        running_loss += loss.detach().item()\n",
    "\n",
    "       \n",
    "        num_batches+=1 \n",
    "        \n",
    "        \n",
    "    # AVERAGE STATS THEN DISPLAY    \n",
    "    total_loss = running_loss/num_batches\n",
    "    loss_list = np.append(loss_list,total_loss)\n",
    "   \n",
    "    elapsed = (time.time()-start)/60\n",
    "        \n",
    "    print('epoch=',epoch, '\\t time=', elapsed,'min', '\\t loss=', total_loss ) \n",
    "    if epoch%50==0:\n",
    "        print(loss_list)\n",
    " \n",
    "print('Finish Training')\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
